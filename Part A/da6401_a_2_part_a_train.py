# -*- coding: utf-8 -*-
"""da6401-a-2-part-a

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/msajid013/da6401-a-2-part-a.6de7d109-130f-48f5-9fa0-a20539857fb6.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250419/auto/storage/goog4_request%26X-Goog-Date%3D20250419T155038Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D93e2f9bfc6574e36c59d4f79159b530d7b52efb82b07c03466c9dd38f766c88e30495fe0c89cde570efd7b1a7c457ea6a94f9b75bcc83f4f83ddd5307558138f302e6d6beb5d777dd70c311f72d03b9e82575fe27404d0c2c464a4b5792af3ab93f57ad582d1bc3b664a21d8bc417c5b169d4cd15e2c026d9d8c13b040c1751a11758af82098234fbc85fdb63292d65266c190bc5933cd83855488a4bd8d8f967385a8d64e10b24d0a2ee24d063fe896ffd87e8b161ed5606f3ec4fd358e2e6232069914eb56e1e855c49ef9f7969b36858cb1e048151b04358fa4449c5b0b02dab3b361c892cc594e74aa68affe145f56af331359add07b60086f98294692e7
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

msajid013_inaturalist_dataset_path = kagglehub.dataset_download('msajid013/inaturalist-dataset')

print('Data source import complete.')

!pip install wandb

import wandb

wandb.login(key='53b259076c07d0811d73bf26bfef7437e04dbf66')

data = '/kaggle/input/inaturalist-dataset'

import os
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Define dataset paths
train_dir = '/kaggle/input/inaturalist-dataset/inaturalist_12K/train'
val_dir = '/kaggle/input/inaturalist-dataset/inaturalist_12K/val'

# List of class names (10 categories in iNaturalist subset)
class_labels = [
    'Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi',
    'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'
]

# Image size to resize for display
image_size = (224, 224)

# Create a figure for visualization (2 rows x 5 columns)
fig = plt.figure(figsize=(20, 10))
num_rows, num_cols, subplot_index = 2, 5, 1

# Display one example image per class from the validation set
for class_name in class_labels:
    class_path = os.path.join(val_dir, class_name)

    for image_file in os.listdir(class_path):
        image_path = os.path.join(class_path, image_file)

        # Read and resize image
        image = mpimg.imread(image_path)
        image = cv2.resize(image, image_size)

        # Add image to subplot
        fig.add_subplot(num_rows, num_cols, subplot_index)
        plt.imshow(image)
        plt.title(class_name)
        plt.axis('off')

        subplot_index += 1
        break  # Show only one image per class

plt.tight_layout()
plt.show()

"""## Question 1"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torchvision.transforms import transforms
from torch.utils.data import DataLoader, SubsetRandomSampler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

# Set device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Helper function to compute output image size after convolution
def compute_output_size(input_size, kernel_size, padding, stride):
    return (1 / 2) * (1 + (input_size - kernel_size + (2 * padding)) / stride)

# Custom Convolutional Neural Network class
class CustomCNN(nn.Module):
    def __init__(self, input_channels=3, conv_filters=[32, 64, 128, 256, 512], kernel_sizes=[3, 3, 5, 5, 7],
                 activation_fn=nn.ReLU(), stride=1, padding=1, pooling_dim=(2, 2), dense_units=512, output_classes=10,
                 dropout_rate=0, use_batchnorm=True):
        super(CustomCNN, self).__init__()
        self.input_channels = input_channels
        self.conv_filters = conv_filters
        self.kernel_sizes = kernel_sizes
        self.activation_fn = activation_fn
        self.stride = stride
        self.padding = padding
        self.pooling_dim = pooling_dim
        self.dense_units = dense_units
        self.output_classes = output_classes
        self.dropout_rate = dropout_rate
        self.use_batchnorm = use_batchnorm

        # Define convolutional and dropout layers
        self.conv1 = nn.Conv2d(self.input_channels, self.conv_filters[0], self.kernel_sizes[0], stride=self.stride, padding=self.padding)
        self.dropout1 = nn.Dropout2d(self.dropout_rate)

        self.conv2 = nn.Conv2d(self.conv_filters[0], self.conv_filters[1], self.kernel_sizes[1], stride=self.stride, padding=self.padding)
        self.dropout2 = nn.Dropout2d(self.dropout_rate)

        self.conv3 = nn.Conv2d(self.conv_filters[1], self.conv_filters[2], self.kernel_sizes[2], stride=self.stride, padding=self.padding)
        self.dropout3 = nn.Dropout2d(self.dropout_rate)

        self.conv4 = nn.Conv2d(self.conv_filters[2], self.conv_filters[3], self.kernel_sizes[3], stride=self.stride, padding=self.padding)
        self.dropout4 = nn.Dropout2d(self.dropout_rate)

        self.conv5 = nn.Conv2d(self.conv_filters[3], self.conv_filters[4], self.kernel_sizes[4], stride=self.stride, padding=self.padding)
        self.dropout5 = nn.Dropout2d(self.dropout_rate)

        # Define batch normalization layers
        self.bn1 = nn.BatchNorm2d(self.conv_filters[0])
        self.bn2 = nn.BatchNorm2d(self.conv_filters[1])
        self.bn3 = nn.BatchNorm2d(self.conv_filters[2])
        self.bn4 = nn.BatchNorm2d(self.conv_filters[3])
        self.bn5 = nn.BatchNorm2d(self.conv_filters[4])

        # Define max pooling layer
        self.pooling = nn.MaxPool2d(self.pooling_dim, stride=2)

        # Compute final image size after convolutions and pooling (assuming input size is 224)
        out_size = 224
        for k in self.kernel_sizes:
            out_size = compute_output_size(out_size, k, self.padding, self.stride)
        out_size = int(out_size)

        # Fully connected layers
        self.flatten_dropout = nn.Dropout1d(self.dropout_rate)
        self.fc1 = nn.Linear(self.conv_filters[4] * out_size * out_size, self.dense_units)
        self.fc1_bn = nn.BatchNorm1d(self.dense_units)
        self.output_layer = nn.Linear(self.dense_units, self.output_classes)

    def forward(self, x):
        # Conv Layer 1
        x = self.conv1(x)
        if self.use_batchnorm: x = self.bn1(x)
        x = self.activation_fn(x)
        x = self.pooling(x)
        x = self.dropout1(x)

        # Conv Layer 2
        x = self.conv2(x)
        if self.use_batchnorm: x = self.bn2(x)
        x = self.activation_fn(x)
        x = self.pooling(x)
        x = self.dropout2(x)

        # Conv Layer 3
        x = self.conv3(x)
        if self.use_batchnorm: x = self.bn3(x)
        x = self.activation_fn(x)
        x = self.pooling(x)
        x = self.dropout3(x)

        # Conv Layer 4
        x = self.conv4(x)
        if self.use_batchnorm: x = self.bn4(x)
        x = self.activation_fn(x)
        x = self.pooling(x)
        x = self.dropout4(x)

        # Conv Layer 5
        x = self.conv5(x)
        if self.use_batchnorm: x = self.bn5(x)
        x = self.activation_fn(x)
        x = self.pooling(x)
        x = self.dropout5(x)

        # Flatten before fully connected layers
        x = x.reshape(x.size(0), -1)

        # Dense Layer
        x = self.fc1(x)
        if self.use_batchnorm: x = self.fc1_bn(x)
        x = self.activation_fn(x)
        x = self.flatten_dropout(x)

        # Output
        x = self.output_layer(x)
        return x

# Instantiate model and send to device
cnn_model = CustomCNN().to(device)
print(cnn_model)

# Function to train the model using training data
def train_model(model, train_loader):
    # Define loss function and optimizer
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    model.train()  # Set model to training mode

    total_loss = 0.0
    total_correct_predictions = 0
    total_samples = 0

    # Loop over batches of training data
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # Reset gradients
        predictions = model(images)  # Forward pass
        loss = loss_function(predictions, labels)  # Compute loss
        loss.backward()  # Backward pass
        optimizer.step()  # Update model parameters

        total_loss += loss.item()

        # Count correct predictions
        _, predicted_labels = torch.max(predictions, 1)
        total_correct_predictions += (predicted_labels == labels).sum().item()
        total_samples += labels.size(0)

    # Calculate average training loss and accuracy
    average_loss = total_loss / len(train_loader)
    training_accuracy = 100 * total_correct_predictions / total_samples

    return model, average_loss, training_accuracy


def evaluate_model(model, data_loader):
    """
    Evaluates the model using a given DataLoader and returns both loss and accuracy.

    Parameters:
    - model: The trained model.
    - data_loader: DataLoader for validation or test data.

    Returns:
    - avg_loss: Average loss over the dataset.
    - accuracy: Accuracy in percentage.
    """
    loss_function = nn.CrossEntropyLoss()  # Define the loss function
    model.eval()  # Set model to evaluation mode
    correct_predictions = 0
    total_predictions = 0
    total_loss = 0.0

    with torch.no_grad():  # No gradient needed during evaluation
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = loss_function(outputs, labels)  # Use predefined loss function
            total_loss += loss.item()

            _, predicted_labels = torch.max(outputs, 1)
            correct_predictions += (predicted_labels == labels).sum().item()
            total_predictions += labels.size(0)

    # Calculate average loss and accuracy
    avg_loss = total_loss / len(data_loader)
    accuracy = 100 * correct_predictions / total_predictions
    return avg_loss, accuracy

# Function to train and validate the model for a number of epochs
def train_and_validate(model, train_loader, val_loader, num_epochs):
    # Define the loss function and optimizer
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Training and validation loop
    for epoch in range(num_epochs):
        # Train the model on the training set
        model, average_train_loss, train_accuracy = train_model(model, train_loader)

        # Validate the model on the validation set
        avg_loss, accuracy = evaluate_model(model, val_loader)

        # Print training and validation performance for the current epoch
        print(f'Epoch {epoch + 1}/{num_epochs}, '
              f'Train Loss: {average_train_loss:.4f}, '
              f'Train Accuracy: {train_accuracy:.2f}%, '
              f'Validation Loss: {avg_loss:.4f}, '
              f'Validation Accuracy: {accuracy:.2f}%')

        # Log training and validation metrics to Weights & Biases
        wandb.log({'Epoch': epoch,
            'Train Loss': average_train_loss,
            'Train Accuracy': train_accuracy,
            'Validation Loss': avg_loss,
            'Validation Accuracy': accuracy})

    print('Model training and validation complete!')

def load_data(data_directory, apply_augmentation):
    """
    Loads image dataset from a given directory with optional data augmentation,
    and splits it into training and validation sets.

    Args:
        data_directory (str): Path to the image dataset.
        apply_augmentation (str): 'Yes' to apply augmentation, else no augmentation.

    Returns:
        train_loader (DataLoader): DataLoader for training dataset.
        val_loader (DataLoader): DataLoader for validation dataset.
    """

    # Define basic image transformations
    resize = transforms.Resize((224, 224))  # Resize to fixed input size
    to_tensor = transforms.ToTensor()       # Convert PIL Image to Tensor
    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize

    # Augmentation-specific transformations
    random_resized_crop = transforms.RandomResizedCrop(224)
    horizontal_flip = transforms.RandomHorizontalFlip()
    color_shift = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)
    rotate = transforms.RandomRotation(20)

    # Define final transformation pipeline
    if apply_augmentation == 'Yes':
        transform_pipeline = transforms.Compose([
            random_resized_crop,
            horizontal_flip,
            color_shift,
            rotate,
            to_tensor,
            normalize
        ])
    else:
        transform_pipeline = transforms.Compose([
            resize,
            to_tensor,
            normalize
        ])

    # Load the dataset using ImageFolder with the defined transformations
    dataset = ImageFolder(root=data_directory, transform=transform_pipeline)

    # Split indices for training and validation (80-20 split)
    train_indices, val_indices = train_test_split(
        list(range(len(dataset))), test_size=0.2, random_state=42
    )

    # Create samplers for each subset
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    # Create DataLoaders for training and validation
    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)
    val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)

    return train_loader, val_loader

# Define configuration for WandB hyperparameter sweep using Bayesian optimization
sweep_configuration = {
    'method': 'bayes',  # Optimization method: Bayesian optimization
    'metric': {
        'name': 'val_accuracy',  # Metric to maximize
        'goal': 'maximize'
    },
    'parameters': {
        # Kernel size configurations for convolutional layers
        'conv_kernel_sizes': {
            'values': [
                [3, 3, 3, 3, 3],
                [3, 5, 5, 7, 7],
                [3, 5, 3, 5, 7],
                [5, 5, 5, 5, 5],
                [7, 7, 7, 7, 7]
            ]
        },
        # Dropout rates to try
        'dropout_rate': {
            'values': [0.3, 0.2]
        },
        # Activation functions to experiment with
        'activation_function': {
            'values': ['relu', 'mish', 'silu', 'gelu']
        },
        # Number of neurons in the fully connected (dense) layer
        'dense_layer_units': {
            'values': [128, 256]
        },
        # Whether to apply Batch Normalization or not
        'use_batch_norm': {
            'values': ['Yes', 'No']
        },
        # Filter (channel) sizes for each convolutional layer
        'conv_filters': {
            'values': [
                [128, 128, 64, 64, 32],
                [32, 64, 128, 256, 512],
                [32, 32, 32, 32, 32],
                [32, 64, 64, 128, 128]
            ]
        },
        # Whether to use data augmentation
        'apply_data_augmentation': {
            'values': ['Yes','No']
        }
    }
}

# Initialize the sweep in the specified WandB project
sweep_id = wandb.sweep(sweep=sweep_configuration, project='DA6401_A-2_Part-A1')

import argparse
import torch
import torch.nn as nn
import wandb
from model import CustomCNN, load_data, train_and_validate

# CLI entry point
def main():
    parser = argparse.ArgumentParser(description="Train CustomCNN with CLI args and log to WandB")

    # Add CLI arguments for sweepable hyperparameters
    parser.add_argument('--data_dir', type=str, required=True, help='Path to dataset directory')
    parser.add_argument('--epochs', type=int, default=6, help='Number of training epochs')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    parser.add_argument('--dropout_rate', type=float, default=0.2, help='Dropout rate')
    parser.add_argument('--dense_units', type=int, default=256, help='Dense layer units')
    parser.add_argument('--apply_augmentation', choices=['Yes', 'No'], default='Yes', help='Apply data augmentation')
    parser.add_argument('--activation_function', choices=['relu', 'mish', 'silu', 'gelu'], default='relu', help='Activation function')
    parser.add_argument('--use_batchnorm', choices=['Yes', 'No'], default='Yes', help='Use batch normalization')
    parser.add_argument('--conv_filters', nargs='+', type=int, default=[32, 64, 128, 256, 512], help='Conv filters (space-separated)')
    parser.add_argument('--conv_kernel_sizes', nargs='+', type=int, default=[3, 3, 5, 5, 7], help='Conv kernel sizes (space-separated)')

    args = parser.parse_args()

    # WandB setup
    wandb.init(project='DA6401_A-2_Part-A1', config=vars(args))
    config = wandb.config

    # Activation function mapping
    activation_map = {
        'relu': nn.ReLU(),
        'gelu': nn.GELU(),
        'silu': nn.SiLU(),
        'mish': nn.Mish()
    }

    # Device setup
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Build model from CLI args
    model = CustomCNN(
        input_channels=3,
        conv_filters=config.conv_filters,
        kernel_sizes=config.conv_kernel_sizes,
        activation_fn=activation_map[config.activation_function],
        dense_units=config.dense_units,
        dropout_rate=config.dropout_rate,
        output_classes=10,
        use_batchnorm=(config.use_batchnorm == 'Yes')
    ).to(device)

    # Load data
    train_loader, val_loader = load_data(config.data_dir, config.apply_augmentation)

    # Train and validate
    train_and_validate(model, train_loader, val_loader, num_epochs=config.epochs)

    wandb.finish()

if __name__ == '__main__':
    main()
